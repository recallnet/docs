---
title: Stateful agents
description: Stateful agents that learn and evolve through memory and collaboration.
keywords: agents, memory, collaboration
---

## What is an agent?

Agents are systems that learn and evolve through memory and collaboration—often used to automate
tasks, solve problems, and make decisions. There are many different types of agents and frameworks
that make it easy to add actions and evaluators as additional tools the agent can use, while also
preserving its knowledge and memory with database storage.

Some popular web3-native frameworks include, all of which offer onchain compatible features:

- [Eliza](https://github.com/elizaOS/eliza)
- [GAME](https://github.com/game-by-virtuals/game-node)
- [ZerePy](https://github.com/blorm-network/ZerePy/)

<Callout type="info">

Many frameworks offer S3-compatible storage, allowing you to store agent data alongside the
[Recall S3 adapter](/advanced/s3). However, we're working to add more Recall-native plugins to make
it easier to store agent data—the first of which is available with
[Eliza and storing CoT logs](/agents/plugins/eliza/cot).

</Callout>

### Agent layers

An agent is made up of four layers:

- **Perception**: Acts as the agent's sensory system, gathering and interpreting data from the
  environment, such as analyzing text / images, or accessing information from external sources.
- **Decision-Making**: Evaluates the perceived information and decides on the appropriate actions to
  take, including reasoning, planning, and strategizing to achieve the agent's goals.
- **Execution**: Carries out the decisions made by the decision-making layer by translating the
  chosen actions into concrete steps within the environment (e.g., sending messages, interacting
  with other agents, or manipulating objects).
- **Memory**: Stores and manages the agent's knowledge and experiences, including short-term memory
  for immediate tasks and long-term memory for accumulated knowledge, allowing the agent to learn
  and adapt over time.

### Memory types

Since Recall can store arbitrary data, there are many ways you can store relevant agent information.
It is important to understand the different types of use cases that can be addressed with the
network.

- **Short-term memory**: Working memory for a single task or decision, like a chatbot interaction
  with a single user and thread.
- **Long-term memory**: Aggregated memory designed to improve the agent's overall intelligence over
  time, consisting of:

  - **Semantic**: General knowledge and facts (e.g., theorems, user preferences, etc.).
  - **Episodic**: Experiences (e.g., past actions and their consequences).
  - **Procedural**: Learned behaviors and patterns (e.g., system prompts, tool usage, etc.).

## Stateful agents

When you use an LLM, it is _stateless_. It will generate a response based on the input and the state
of the model at the time, but that's it. With a _stateful_ agent, you can store information between
interactions to improve the agent's performance over time.

For example, a stateful agent will have both working and long-term memories, allowing it to:

- Use past actions and their consequences to inform future actions.
- Use general knowledge and facts to inform future actions.
- Use past experiences to inform future actions.

As the agent progressively uses more data and performs more actions, it can store that data on
Recall and load it into its context. Particularly, data like CoT and related reasoning can be
particularly helpful for the model to better understand what _thinking_ steps it has take in the
past—and not solely the action it took.
